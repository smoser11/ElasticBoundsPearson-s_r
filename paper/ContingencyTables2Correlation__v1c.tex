% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{mathpazo}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{proposition}{Proposition}
\usepackage{float}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage[style=apa,sorting=nyt]{biblatex}
\addbibresource{references.bib}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Elastic Bounds of Pearson's r: Theoretical and Empirical Insights for Ordinal Data},
  pdfauthor={Cees van der Eijk; Scott Moser},
  colorlinks=true,
  linkcolor={black},
  filecolor={Maroon},
  citecolor={RoyalBlue},
  urlcolor={BrickRed},
  pdfcreator={LaTeX via pandoc}}


\title{Elastic Bounds of Pearson's \(r\): Theoretical and Empirical
Insights for Ordinal Data}
\author{Cees van der Eijk \and Scott Moser}
\date{}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}

\begin{abstract}
Pearson’s correlation coefficient $r$, when applied to ordinal data, is subject to elasticity due to constraints from marginal distributions. This paper develops theoretical bounds for $r$, based on Boole–Fréchet–Hoeffding inequalities and rearrangement inequalities, and derives analytic expressions for their limits. We investigate when symmetry in the bounds holds or breaks, and explore practical implications for correlation-based methods like PCA and SEM. An accompanying R package allows users to compute bounds and perform hypothesis tests given fixed marginals.
\end{abstract}

\section{Introduction and Motivation}\label{introduction-and-motivation}

\begin{itemize}
\item
  The widespread use of Pearson's \(r\) with ordinal data.\\
\item
  The problem of elasticity: how max/min bounds of \(r\) vary with
  marginals.\\
\item
  Contributions:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Theory of optimal bounds\\
  \item
    Symmetry-breaking conditions\\
  \item
    Empirical consequences\\
  \item
    Supporting tools
  \end{enumerate}
\end{itemize}

\section{Background and Definitions}\label{background-and-definitions}

\begin{itemize}
\tightlist
\item
  Ordinal data and assumptions of interval-scale correlation\\
\item
  Existing alternatives: Spearman, polychoric, polyserial; their
  strengths and limitations\\
\item
  Coupling and rearrangement in discrete settings
\end{itemize}

\section{Theoretical Framework}\label{theoretical-framework}

\subsection{Optimal Coupling and Correlation
Bounds}\label{optimal-coupling-and-correlation-bounds}

We formalize the problem of identifying the joint distribution
(coupling) of two ordinal variables with fixed marginals that maximizes
or minimizes the Pearson correlation.

\begin{proposition}


Let $X$ and $Y$ be discrete ordinal random variables, each with finite ordered support:

$$
X: x_1 < x_2 < \dots < x_{K_X},\quad Y: y_1 < y_2 < \dots < y_{K_Y}
$$

with marginal probability distributions $p_X(x_i) = P(X = x_i)$, $p_Y(y_j) = P(Y = y_j)$, respectively.

Then, the maximum and minimum values of the Pearson correlation coefficient $r_{XY}$, consistent with the fixed marginals, are obtained as follows:

- Maximum $r_{XY}$: achieved by pairing largest $X$-values with largest $Y$-values (comonotonic arrangement).
    
- Minimum $r_{XY}$: achieved by pairing largest $X$-values with smallest $Y$-values (anti-comonotonic arrangement).
    
\end{proposition}

\begin{proof}



The Pearson correlation coefficient is given by:

$$r_{XY} = \frac{E[XY] - E[X]E[Y]}{\sigma_X \sigma_Y}.$$

Given fixed marginals $p_X(x_i)$, $p_Y(y_j)$, the expectations $E[X], E[Y]$ and standard deviations $\sigma_X, \sigma_Y$ are constant. Thus, to maximize or minimize $r_{XY}$, we only need to maximize or minimize the expectation $E[XY]$:

$$E[XY] = \sum_{i=1}^{K_X}\sum_{j=1}^{K_Y} x_i y_j P(X = x_i, Y = y_j).$$

This proof relies on a rearrangement inequality of @hard52-inequalities (Theorem 368):

For real sequences $a_1 \leq a_2 \leq \dots \leq a_n$ and $b_1 \leq b_2 \leq \dots \leq b_n$, and for any permutation $\pi$ of indices $\{1,\dots,n\}$ we have the following:

    

$$a_1 b_1 + a_2 b_2 + \dots + a_n b_n \geq a_1 b_{\pi(1)} + a_2 b_{\pi(2)} + \dots + a_n b_{\pi(n)}$$
and
 
    
$$a_1 b_n + a_2 b_{n-1} + \dots + a_n b_1 \leq a_1 b_{\pi(1)} + a_2 b_{\pi(2)} + \dots + a_n b_{\pi(n)}$$

Equality occurs only if the permutation $\pi$ is monotonically increasing (for maximum) or monotonically decreasing (for minimum).



To explicitly connect this to our problem, enumerate observations explicitly from sorted marginals:
    
        $$X_{\downarrow}: x_{[K_X]} \geq x_{[K_X-1]} \geq \dots \geq x_{[1]}, \quad  
        Y_{\downarrow}: y_{[K_Y]} \geq y_{[K_Y-1]} \geq \dots \geq y_{[1]}.$$
(Sorted in descending order for maximization)
* Expand discrete probability distributions into explicit observation-level sequences. 
If $K_X \neq K_Y$, extend the shorter sequence with zero-probability categories so both sequences have equal length, which does not affect marginal probabilities or correlation.

Hence, to maximize $E[XY]$: pair the largest ranks of $X$ with the largest ranks of $Y$. Explicitly, start from the top (highest values) and move downward:
    
- Pair as many observations of the largest $X$-category as possible with the largest $Y$-category, then next-largest, etc., until all observations are paired.
        
- By the Hardy–Littlewood–Pólya Rearrangement Inequality, this explicitly constructed pairing yields the maximum possible sum of products, hence maximizing $E[XY]$.
    

Likewise, to minimize $E[XY]$ pair the largest $X$-categories with the smallest $Y$-categories, then second-largest $X$-categories with second-smallest $Y$-categories, and so forth (anti-comonotonic ordering).   By the rearrangement inequality, this arrangement explicitly yields the minimal sum of products, hence minimizing $E[XY]$.
    


\end{proof}

In words, given fixed marginals, we have shown:

\begin{itemize}
\item
  \textbf{Maximum correlation \(r_{\text{max}}\)} is achieved by
  comonotonic arrangement:

  \[P_{\text{max}}(X=x_{[i]}, Y=y_{[i]}) \quad\text{in descending order.}\]
\item
  \textbf{Minimum correlation \(r_{\text{min}}\)} is achieved by
  anti-comonotonic arrangement:

  \[P_{\text{min}}(X=x_{[i]}, Y=y_{[n+1-i]}) \quad\text{pairing descending X with ascending Y.}\]
\end{itemize}

With this explicit construction we can simply calculate \(r_{max}\) and
\(r_{min}\) when the values of \(X\) and \(Y\) are ranks.

\begin{proposition}[Corollary: Analytic Forms for $r_{\min}$ and $r_{\max}$]


Let two ordinal variables $X$ and $Y$ have values as follows:

* $X$ with $K_X$ ordinal levels: $1,2,\dots,K_X$
    
* $Y$ with $K_Y$ ordinal levels: $1,2,\dots,K_Y$
    

with absolute frequencies:

- $n_{X}(i)$, number of observations at level $i$ of $X$.
    
- $n_{Y}(j)$, number of observations at level $j$ of $Y$.
    

Then the maximum Pearson correlation is:

$$r_{\text{max}} = \frac{E[XY]_{\text{max}} - \bar{X}\bar{Y}}{\sigma_X \sigma_Y}.$$
Where 

$$
E[XY]_{\max} =\frac{1}{N}\sum_{i=1}^{K_X}\sum_{j=1}^{K_Y}x_i y_j M_{i,j}
$$

where explicitly defined frequencies $M_{i,j}$ pair observations in a comonotonic manner, calculated explicitly via the greedy iterative approach as follows.  

Define the matrix $M_{i,j}$, the frequency with which the level $x_i$ pairs with the level $y_j$. Clearly, we must have:

$$\sum_j M_{i,j}=n_X(i),\quad\sum_i M_{i,j}=n_Y(j)$$

**Algorithm for explicit calculation of $M_{i,j}$** (greedy method):

\begin{algorithm}

Initialize available frequencies explicitly:  $n'_Y(j)=n_Y(j)\quad\text{for each }j$

- For each level $x_i$, from smallest $i=1$ to largest:
    
    - For each level $y_j$, from smallest $j=1$ to largest:
        
        - Pair as many observations as possible:
            

$$M_{i,j}=\min\left(n_X(i)-\sum_{s=1}^{j-1}M_{i,s},\, n'_Y(j)\right)$$

Next, update explicitly: $$n'_Y(j)\leftarrow n'_Y(j)-M_{i,j}$$

\end{algorithm}


Similarly, the minimum Pearson correlation ($r_{\text{min}}$) achieved by anti-comonotonic alignment (pairing largest ranks of $X$ with smallest ranks of $Y$) is explicitly:
$$r_{\text{min}} = \frac{E[XY]_{\text{min}} - \bar{X}\bar{Y}}{\sigma_X \sigma_Y}.$$



\end{proposition}

\begin{proof}

Let the total number of observations be $N$, thus:

$$\sum_{i=1}^{K_X} n_{X}(i) = N,\quad \sum_{j=1}^{K_Y} n_{Y}(j) = N.$$

Means and standard deviations clearly become:

Means:
    
$$
\bar{X} = \frac{1}{N}\sum_{i=1}^{K_X} i \cdot n_X(i),\quad  
    \bar{Y} = \frac{1}{N}\sum_{j=1}^{K_Y} j \cdot n_Y(j).
$$
Standard deviations:
    
$$
\sigma_X = \sqrt{\frac{1}{N}\sum_{i=1}^{K_X} (i - \bar{X})^2 n_X(i)},\quad  
    \sigma_Y = \sqrt{\frac{1}{N}\sum_{j=1}^{K_Y} (j - \bar{Y})^2 n_Y(j)}.
$$


To achieve the maximum expected product $E[XY]_{\text{max}}$, do the following:
First *sort* ranks from largest to smallest for both $X$ and $Y$; then *pair* ranks directly from highest to lowest available observations.
    




**Minimum Expectation**
  

Define explicitly a matrix $R_{i,j}$ giving frequencies of pairings $X=x_i$ with $Y=y_j$. For the minimal expectation, pair largest available $X$-values explicitly with smallest available $Y$-values first (greedy algorithm):

Initialize explicitly available frequencies:
    

$$n'_Y(j)=n_Y(j)\quad\text{for each }j$$

* For $i$ from largest to smallest ($i=K_X$ down to $1$):
    
    * For $j$ from smallest to largest ($j=1$ up to $K_Y$):
        
        * Pair explicitly as many observations as possible:
            

$$R_{i,j}=\min\left(n_X(i)-\sum_{s=1}^{j-1}R_{i,s},\, n'_Y(j)\right)$$

Update explicitly available frequencies:


$$n'_Y(j)\leftarrow n'_Y(j)-R_{i,j}$$

Then explicitly the minimal expectation is:

$$E[XY]_{\text{min}}=\frac{1}{N}\sum_{i=1}^{K_X}\sum_{j=1}^{K_Y} x_i y_j R_{i,j}$$

  

This explicit equation applies Whitt’s rearrangement theorem (@whit76-bivariate),  ensuring proper maximal pairing of ranks.

The formula for $E[XY]_{\text{min}}$ is derived in a similar maner.

\end{proof}

\textbf{Discussion}

We want to construct a joint distribution table \(M\) such that:

\begin{itemize}
\item
  The \textbf{row sums} match the marginal counts for \(X\):
  \(\sum_j M_{i,j} = n_X(i)\)
\item
  The \textbf{column sums} match the marginal counts for \(Y\):
  \(\sum_i M_{i,j} = n_Y(j)\)
\end{itemize}

To do this, we go \textbf{greedily}, pairing the highest available \(X\)
values with the \textbf{smallest available} \(Y\) values, one cell at a
time.

To avoid \textbf{exceeding} the available marginal totals in \(Y\), we
must track how much of \(n_Y(j)\) is \textbf{still unassigned} at each
step --- and that's what \(n_Y'(j)\) represents.\\
After assigning \(M_{i,j}\) units to the cell \((i,j)\), we subtract
that amount from the remaining pool of level \(y_j\) values, like this:
\(n_Y'(j) \leftarrow n_Y'(j) - M_{i,j}\)This ensures we don't
\textbf{overfill} any column of the matrix.

To maximize the expectation \(E[XY]\), the rearrangement inequality
states we must pair values of \(X\) and \(Y\) from smallest-to-smallest,
second-smallest-to-second-smallest, and so forth (comonotonic
alignment).

Thus, explicitly:

\begin{itemize}
\tightlist
\item
  Sort \(X\): lowest-to-highest:
\end{itemize}

\[X_{\text{sorted}} = (\underbrace{x_1,\dots,x_1}_{n_X(1)}, \underbrace{x_2,\dots,x_2}_{n_X(2)}, \dots,\underbrace{x_{K_X},\dots,x_{K_X}}_{n_X(K_X)})\]

Sorted \(Y\)-values (ascending order for max, descending for min):

\[Y_{\text{sorted(max)}} = (\underbrace{y_1,\dots,y_1}_{n_Y(1)}, \underbrace{y_2,\dots,y_2}_{n_Y(2)}, \dots,\underbrace{y_{K_Y},\dots,y_{K_Y}}_{n_Y(K_Y)})\]

\[Y_{\text{sorted(min)}} = (\underbrace{y_{K_Y},\dots,y_{K_Y}}_{n_Y(K_Y)}, \underbrace{y_{K_Y-1},\dots,y_{K_Y-1}}_{n_Y(K_Y-1)}, \dots,\underbrace{y_1,\dots,y_1}_{n_Y(1)})\]

The maximum and minimum expectations are simply:

\begin{itemize}
\tightlist
\item
  \textbf{Maximum expectation} (pair element-by-element):
\end{itemize}

\[E[XY]_{\text{max}} = \frac{1}{N}\sum_{k=1}^{N} X_{\text{sorted}}(k)\cdot Y_{\text{sorted(max)}}(k)\]

\begin{itemize}
\tightlist
\item
  \textbf{Minimum expectation}:
\end{itemize}

\[E[XY]_{\text{min}} = \frac{1}{N}\sum_{k=1}^{N} X_{\text{sorted}}(k)\cdot Y_{\text{sorted(min)}}(k)\]

Then the maximum expectation explicitly is:

\[E[XY]_{\text{max}}=\frac{1}{N}\sum_{k=1}^{N}X_{\text{sorted}}(k)\cdot Y_{\text{sorted(max)}}(k)\]
And similarly for the minimum:
\[E[XY]_{\text{min}}=\frac{1}{N}\sum_{k=1}^{N}X_{\text{sorted}}(k)\cdot Y_{\text{sorted(min)}}(k)\]

\subsection{Fréchet--Hoeffding and Boole--Fréchet
Inequalities}\label{fruxe9chethoeffding-and-boolefruxe9chet-inequalities}

These classical bounds define feasible joint distributions given
marginals and constrain the attainable values of \(r\).

\subsection{Symmetry and the Role of
Ties}\label{symmetry-and-the-role-of-ties}

\begin{itemize}
\tightlist
\item
  Conditions under which \(r_{\min} = -r_{\max}\)
\item
  How ties in marginal distributions affect the attainability of the
  lower bound
\end{itemize}

\subsection{Special Cases and Boundary
Conditions}\label{special-cases-and-boundary-conditions}

\begin{itemize}
\tightlist
\item
  Equal vs.~unequal numbers of categories\\
\item
  Symmetric vs.~asymmetric marginal distributions
\end{itemize}

\subsection{Relation to Copula Theory
(Optional)}\label{relation-to-copula-theory-optional}

Although our setting is discrete, the problem is conceptually linked to
copula-based modeling of dependence with fixed marginals. The connection
is discussed as a direction for future work.

\section{Empirical Illustration and Practical
Relevance}\label{empirical-illustration-and-practical-relevance}

\subsection{Effects of Marginal
Shapes}\label{effects-of-marginal-shapes}

\begin{itemize}
\tightlist
\item
  Shape-based elasticity of correlation bounds\\
\item
  Influence of skewness, modality, and entropy
\end{itemize}

\subsection{Symmetry Breaking in Correlation
Bounds}\label{symmetry-breaking-in-correlation-bounds}

\begin{itemize}
\tightlist
\item
  When and why \(r_{\min} \neq -r_{\max}\)
\item
  Empirical indicators of bound asymmetry
\end{itemize}

\subsection{Applications and
Implications}\label{applications-and-implications}

\begin{itemize}
\tightlist
\item
  Impact on PCA, factor analysis, and SEM using ordinal data\\
\item
  Practical risks: over-factoring, biased structural coefficients\\
\item
  Recommendations for interpreting Pearson's \(r\) in applied contexts
\end{itemize}

\section{Extensions and Open
Questions}\label{extensions-and-open-questions}

\begin{itemize}
\tightlist
\item
  Role of entropy and joint uncertainty in bounding behavior\\
\item
  Probabilistic modeling over the \(r \in [r_{\min}, r_{\max}]\)
  interval\\
\item
  Possibility of adjusting or normalizing \(r\)
\end{itemize}

\section{Conclusion}\label{conclusion}

\begin{itemize}
\tightlist
\item
  Summary: Theoretical bounds, symmetry-breaking conditions, and
  implications for applied research\\
\item
  An R package accompanies this paper, providing tools to compute
  max/min bounds and perform randomization-based hypothesis tests for
  fixed marginals. Details are available in the appendix and online.\\
\item
  Future work: deeper integration with copula models, correction
  strategies, and generalizations to higher dimensions
\end{itemize}

\newpage

\section{References}\label{references}

\printbibliography[heading=none]

\newpage

\section{Appendix A: Mathematical
Proofs}\label{appendix-a-mathematical-proofs}

\begin{itemize}
\tightlist
\item
  Formal derivations of optimal coupling and analytical bounds
\end{itemize}

\section{Appendix B: Software Tools and Code
Listings}\label{appendix-b-software-tools-and-code-listings}

\begin{itemize}
\tightlist
\item
  Documentation and examples for the R package\\
\item
  Description of randomization testing features
\end{itemize}

\section{Appendix C: Additional Tables and
Simulations}\label{appendix-c-additional-tables-and-simulations}

\begin{itemize}
\tightlist
\item
  Supplementary empirical examples, simulation results
\end{itemize}





\end{document}
